{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMtxbByiJnkGeN96FOJdRxt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/madhura2024/myAI_MODELS/blob/main/sentiment_analyis_summarization_deep_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "STARTING DEEP LEARNING ( making sentiment analysis and summarization using deep learning )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "   2 TYPES OF CLEANING ----------------->>>>>>>>>>    \n",
        "1. structural ( drop , duplicates , strip , dummy etc )\n",
        "2. textual ( sub , lower etc )\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "uKmQz3X8ibTL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "model = pd.read_csv(\"https://zenodo.org/record/10157504/files/Musical_instruments_reviews2.csv\")\n",
        "# print(model.columns)\n",
        "model = model.head(10)\n",
        "model = model.dropna(subset=['reviewText']).drop_duplicates(subset=['reviewText'])\n",
        "# model------------>>>>>>>> is your whole table.model.               ['text'] --------------->>>>>>>>>Just one column from the table â€” the part with your actual sentences or words.\n",
        "model['reviewText'] = model['reviewText'].astype(str).str.strip()\n"
      ],
      "metadata": {
        "id": "3TrUAxgSjFxb"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re  # Get the magic toolbox for finding and replacing stuff in text\n",
        "import nltk  # Bring in the big NLP helper library\n",
        "from nltk.corpus import stopwords  # Grab the list of boring common words like \"the\" and \"and\"\n",
        "\n",
        "nltk.download('stopwords')  # Download that boring word list once so we can use it\n",
        "stop_words = set(stopwords.words(\"english\"))  # Put those boring words in a fast-check list\n",
        "\n",
        "def clean_text(text):\n",
        "    text = text.lower()  # Make all letters small so \"Hello\" and \"hello\" look the same\n",
        "    text = re.sub(r\"http\\S+|www\\S+|<.*?>|[^a-z\\s]\", \" \", text)  # Trash links, weird tags, and weird symbols with a space\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()  # Squish many spaces into one and wipe spaces at the ends\n",
        "    return \" \".join(word for word in text.split() if word not in stop_words)  # Kick out boring words and glue what's left back together"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSP0GKLgjmx6",
        "outputId": "48c3699c-fde1-4b4f-cb99-64b12c6f57c6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "to check sentiment we have a column called overall where there are stars. think of it as a column array . use for loop and if else to dtermine mood."
      ],
      "metadata": {
        "id": "M82fmApqtLVz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentiments = []\n",
        "\n",
        "for i in range(len(model['overall'])):\n",
        "    rating = model['overall'][i]\n",
        "    if rating >= 4:\n",
        "        sentiments.append(\"happy\")\n",
        "    elif rating <= 2:\n",
        "        sentiments.append(\"sad\")\n",
        "    else:\n",
        "        sentiments.append(\"neutral\")\n",
        "\n",
        "model['sentiment'] = sentiments\n"
      ],
      "metadata": {
        "id": "6AULyzOaq7nN"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "call"
      ],
      "metadata": {
        "id": "DLtX62gvvDMT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model['clean_review'] = model['reviewText'].apply(clean_text)"
      ],
      "metadata": {
        "id": "XhAJ70GQy4Km"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "sentiment"
      ],
      "metadata": {
        "id": "9hzH-xbQ4c6P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "sentiment_pipeline = pipeline(\"sentiment-analysis\")\n",
        "\n",
        "sentiment_results = []\n",
        "\n",
        "for text in model['reviewText']:\n",
        "    result = sentiment_pipeline(text[:512])\n",
        "    sentiment_results.append(result[0]['label'])\n",
        "\n",
        "model['sentiment'] = sentiment_results\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7aId0ZkW4fL4",
        "outputId": "8bd0e38d-e6db-4e52-bfa4-457d18ffcc69"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "summarize"
      ],
      "metadata": {
        "id": "OH0e3vIy4lD2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "summarizer = pipeline(\"summarization\")\n",
        "\n",
        "summaries = []\n",
        "\n",
        "for text in model['reviewText']:\n",
        "    if len(text) > 20:\n",
        "        result = summarizer(text[:1000])\n",
        "        summaries.append(result[0]['summary_text'])\n",
        "    else:\n",
        "        summaries.append(\"Too short to summarize\")\n",
        "\n",
        "model['summary'] = summaries"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14VfQYMU4nPs",
        "outputId": "9499158d-6a3d-43b9-b4c8-936ae4f75e52"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Device set to use cpu\n",
            "Your max_length is set to 142, but your input_length is only 61. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=30)\n",
            "Your max_length is set to 142, but your input_length is only 124. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=62)\n",
            "Your max_length is set to 142, but your input_length is only 87. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=43)\n",
            "Your max_length is set to 142, but your input_length is only 45. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=22)\n",
            "Your max_length is set to 142, but your input_length is only 34. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=17)\n",
            "Your max_length is set to 142, but your input_length is only 56. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=28)\n",
            "Your max_length is set to 142, but your input_length is only 44. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=22)\n",
            "Your max_length is set to 142, but your input_length is only 48. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=24)\n",
            "Your max_length is set to 142, but your input_length is only 48. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=24)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "time taking so check just a few"
      ],
      "metadata": {
        "id": "uhlA4oZP5EQR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(model[['reviewText', 'sentiment', 'summary']].head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16_SnkrA5HbI",
        "outputId": "2e8564e5-b24f-4f45-fb72-306666a5ba72"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                          reviewText sentiment  \\\n",
            "0  Not much to write about here, but it does exac...  POSITIVE   \n",
            "1  The product does exactly as it should and is q...  POSITIVE   \n",
            "2  The primary job of this device is to block the...  NEGATIVE   \n",
            "3  Nice windscreen protects my MXL mic and preven...  NEGATIVE   \n",
            "4  This pop filter is great. It looks and perform...  POSITIVE   \n",
            "5  So good that I bought another one.  Love the h...  POSITIVE   \n",
            "6  I have used monster cables for years, and with...  POSITIVE   \n",
            "7  I now use this cable to run from the output of...  NEGATIVE   \n",
            "8  Perfect for my Epiphone Sheraton II.  Monster ...  POSITIVE   \n",
            "9  Monster makes the best cables and a lifetime w...  POSITIVE   \n",
            "\n",
            "                                             summary  \n",
            "0   It is one of the lowest prices pop filters on...  \n",
            "1   The product does exactly as it should and is ...  \n",
            "2   The device blocks the breath that would other...  \n",
            "3   Nice windscreen protects my MXL mic and preve...  \n",
            "4   This pop filter is great. It looks and perfor...  \n",
            "5   Bass sounds great. So good that I bought anot...  \n",
            "6   The lifetime warranty is worth the price alon...  \n",
            "7   After I bought Monster Cable to hook up my pe...  \n",
            "8   Monster cables are well constructed . Perfect...  \n",
            "9   Monster makes the best cables and a lifetime ...  \n"
          ]
        }
      ]
    }
  ]
}